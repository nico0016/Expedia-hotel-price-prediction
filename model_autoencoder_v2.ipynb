{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/SI699')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preprocess():\n",
    "    \n",
    "    def __init__(self, train_file_path, test_file_path):\n",
    "        self.train_file_path = train_file_path\n",
    "        self.test_file_path = test_file_path\n",
    "        self.all_data = pd.DataFrame()\n",
    "        self.sampled_data = pd.DataFrame()\n",
    "    \n",
    "    def load_data(self):\n",
    "        train = pd.read_csv(self.train_file_path)\n",
    "        test = pd.read_csv(self.test_file_path)\n",
    "        print('training data has %d records'%len(train))\n",
    "        print('test data has %d records'%len(test))\n",
    "        \n",
    "        # drop columns in training data that are not available in test data set, including :'position', 'click_bool', 'gross_bookings_usd', 'booking_bool'\n",
    "        cols_train_only = [col for col in train.columns.unique().tolist() if col not in test.columns.unique().tolist()]\n",
    "        print('Columns only available in training data:',cols_train_only)\n",
    "        train = train.drop(columns = cols_train_only)\n",
    "\n",
    "        # combine train and test data\n",
    "        self.all_data = pd.concat([train, test], ignore_index=True)\n",
    "        print('Whole dataset has %d records' % len(self.all_data))\n",
    "        \n",
    "        # convert 'date_time' to datatime object\n",
    "        self.all_data['date_time'] = pd.to_datetime(self.all_data.date_time)\n",
    "        self.all_data.sort_values(by=['date_time'],inplace=True)\n",
    "        self.all_data = self.all_data.reset_index(drop=True)\n",
    "        return self.all_data\n",
    "    \n",
    "    def clean_data(self,data, output_file_name):\n",
    "        # handle NA values\n",
    "        NA_columns = []\n",
    "        for col in data.columns.unique().tolist():\n",
    "            if data[col].isna().values.any() == True:\n",
    "                NA_columns.append(col)\n",
    "        for col in NA_columns:\n",
    "            # create binary columns\n",
    "            new_col = 'new_'+ col\n",
    "            data[new_col] = data[col].apply(lambda x: 1 if x >= 0 else 0)\n",
    "        # replace old column NA values to median value\n",
    "        data = data.fillna(data.median())\n",
    "        # output to csv file\n",
    "        data.to_csv(output_file_name +'.csv',index = False, encoding = 'utf-8')\n",
    "        return data\n",
    "    \n",
    "    def sample_data(self,sample_size):\n",
    "        interval_range = len(self.all_data)//sample_size\n",
    "        mid_idx_lst = []\n",
    "        for i in range(1,sample_size+1):\n",
    "            mid_idx = (interval_range*(i-1) + interval_range*i)//2\n",
    "            mid_idx_lst.append(mid_idx)\n",
    "        self.sampled_data = self.all_data.iloc[mid_idx_lst]\n",
    "        return self.sampled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data has 9917530 records\n",
      "test data has 6622629 records\n",
      "Columns only available in training data: ['position', 'click_bool', 'gross_bookings_usd', 'booking_bool']\n",
      "Whole dataset has 16540159 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/leetcode/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data_p = Data_preprocess('./expedia_data/train.csv','./expedia_data/test.csv')\n",
    "all_data = data_p.load_data()\n",
    "sampled_data = data_p.sample_data(5000)\n",
    "# cleaned_data = data_p.clean_data(all_data,'res/cleaned_data')\n",
    "cleaned_sampled_data = data_p.clean_data(sampled_data,'res/cleaned_sampled_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modeling_pipeline():\n",
    "    def __init__(self,data,model,variables):\n",
    "        self.data = data.iloc[:]\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.model = model\n",
    "        self.variables = variables\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.X_val = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.y_val = pd.DataFrame()\n",
    "    \n",
    "    def split_data(self):\n",
    "        training_size_large = int(len(self.data) * 0.8)   \n",
    "        validation_size = int(training_size_large * 0.2)\n",
    "        training_size = training_size_large - validation_size\n",
    "        test_size = int(len(self.data) * 0.2)\n",
    "        print('training size: %d'%training_size)\n",
    "        print('validation size: %d'%validation_size)\n",
    "        print('test size: %d'%test_size)\n",
    "        # split data by temporal order\n",
    "        self.train_data = self.data.iloc[0: training_size]\n",
    "        self.val_data = self.data.iloc[training_size:(training_size + validation_size)]\n",
    "        self.test_data = self.data.iloc[(training_size + validation_size): (training_size + validation_size + test_size)]\n",
    "        return self.train_data, self.val_data, self.test_data\n",
    "    \n",
    "    def get_X_y(self):\n",
    "        # TODO: need to handle 'date_time' properly\n",
    "        # for now, leave out \"date_time\" from modeling\n",
    "        #variables = [col for col in self.data.columns.unique().tolist() if col not in ['price_usd','date_time']]\n",
    "        self.X_train = self.train_data[self.variables]\n",
    "        self.y_train = self.train_data['price_usd']\n",
    "        self.X_val = self.val_data[variables]\n",
    "        self.y_val = self.val_data['price_usd']\n",
    "        self.X_test = self.test_data[self.variables]\n",
    "        self.y_test = self.test_data['price_usd']\n",
    "        return self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test\n",
    "    \n",
    "    \n",
    "    def get_RMSE(self,y_pred,y_true,data):\n",
    "        return np.sqrt(sum((y_pred - y_true)**2)/len(data))\n",
    "    \n",
    "    def get_modeling_result(self):\n",
    "        reg = self.model.fit(self.X_train, self.y_train)\n",
    "        y_pred_val = reg.predict(self.X_val)\n",
    "        y_pred_train = reg.predict(self.X_train)\n",
    "        val_RMSE = self.get_RMSE(y_pred_val, self.y_val, self.val_data)\n",
    "        train_RMSE = self.get_RMSE(y_pred_train ,self.y_train, self.train_data)\n",
    "        print('training RMSE:',train_RMSE)\n",
    "        print('valiation RMSE:',val_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [col for col in all_data.columns.unique().tolist() if col not in ['price_usd','date_time']]\n",
    "model_p = modeling_pipeline(cleaned_sampled_data, LinearRegression(), variables)\n",
    "train_data, val_data, test_data = model_p.split_data()\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = model_p.get_X_y()\n",
    "model_p.get_modeling_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide variables into categories\n",
    "# get categorical variables\n",
    "categorical_vars = ['srch_id','site_id','visitor_location_country_id','visitor_hist_starrating','prop_country_id','prop_id','prop_starrating',\n",
    "'srch_destination_id']\n",
    "other_cols = [col for col in variables if col not in categorical_vars]\n",
    "# get categorical binary variables\n",
    "categorical_binary_vars = []\n",
    "categorical_binary_vars += ['promotion_flag']\n",
    "categorical_binary_vars += [col for col in sampled_data if col.startswith('new')]\n",
    "categorical_binary_vars += [col for col in sampled_data if col.endswith('inv')]\n",
    "categorical_binary_vars += [col for col in sampled_data if col.endswith('bool')]\n",
    "# get continous variables\n",
    "continous_vars = [ col for col in variables if (col not in categorical_binary_vars) & (col not in categorical_vars )]\n",
    "print (\"categorical binary vars: \", len(categorical_binary_vars))\n",
    "print (\"categorical non binary vars: \", len(categorical_vars))\n",
    "print (\"continues vars: \", len(continous_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
