{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/liyuan/desktop/SI699/codes')\n",
    "\n",
    "# Put this when it's called\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "class modeling_pipeline():\n",
    "    def __init__(self,data,model,variables):\n",
    "        self.data = data.iloc[:]\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.val_data = pd.DataFrame()\n",
    "        self.test_data = pd.DataFrame()\n",
    "        self.model = model\n",
    "        self.variables = variables\n",
    "        self.X_train = pd.DataFrame()\n",
    "        self.X_test = pd.DataFrame()\n",
    "        self.X_val = pd.DataFrame()\n",
    "        self.y_train = pd.DataFrame()\n",
    "        self.y_test = pd.DataFrame()\n",
    "        self.y_val = pd.DataFrame()\n",
    "\n",
    "        self.categorical_vars = ['srch_id','site_id','visitor_location_country_id','visitor_hist_starrating','prop_country_id','prop_id',\n",
    "        'srch_destination_id']\n",
    "\n",
    "        self.categorical_binary_vars = []\n",
    "        self.continuous_vars = []\n",
    "\n",
    "        self.X_train_normalized = pd.DataFrame()\n",
    "        self.X_val_normalized = pd.DataFrame()\n",
    "        self.X_test_normalized = pd.DataFrame()\n",
    "\n",
    "        self.X_train_standardized = pd.DataFrame()\n",
    "        self.X_val_standardized = pd.DataFrame()\n",
    "        self.X_test_standardized = pd.DataFrame()\n",
    " \n",
    "    def split_data(self):\n",
    "        training_size_large = int(len(self.data) * 0.8)   \n",
    "        validation_size = int(training_size_large * 0.2)\n",
    "        training_size = training_size_large - validation_size\n",
    "        test_size = int(len(self.data) * 0.2)\n",
    "        print('training size: %d'%training_size)\n",
    "        print('validation size: %d'%validation_size)\n",
    "        print('test size: %d'%test_size)\n",
    "        # split data by temporal order\n",
    "        self.train_data = self.data.iloc[0: training_size]\n",
    "        self.val_data = self.data.iloc[training_size:(training_size + validation_size)]\n",
    "        # self.test_data = self.data.iloc[(training_size + validation_size): (training_size + validation_size + test_size)]\n",
    "        self.test_data = self.data.iloc[(training_size + validation_size):]\n",
    "        return self.train_data, self.val_data, self.test_data\n",
    "    \n",
    "    def divide_variables(self):\n",
    "        # divide variables into categories\n",
    "        # get categorical variables\n",
    "        other_cols = [col for col in self.variables if col not in self.categorical_vars]\n",
    "        # get categorical binary variables\n",
    "        self.categorical_binary_vars += ['promotion_flag']\n",
    "        self.categorical_binary_vars += [col for col in self.data if col.startswith('new')]\n",
    "        self.categorical_binary_vars += [col for col in self.data if col.endswith('inv')]\n",
    "        self.categorical_binary_vars += [col for col in self.data if col.endswith('bool')]\n",
    "        # get continous variables\n",
    "        self.continuous_vars += [ col for col in self.variables if (col not in self.categorical_binary_vars) & (col not in self.categorical_vars )]\n",
    "        print (\"categorical binary vars: \", len(self.categorical_binary_vars))\n",
    "        print (\"categorical non binary vars: \", len(self.categorical_vars))\n",
    "        print (\"continues vars: \", len(self.continuous_vars))\n",
    "        return self.categorical_vars, self.categorical_binary_vars, self.continuous_vars\n",
    "\n",
    "    def get_X_y(self):\n",
    "        # TODO: need to handle 'date_time' properly\n",
    "        # for now, leave out \"date_time\" from modeling\n",
    "        # self.variables += [col for col in self.data.columns.unique().tolist() if col not in ['price_usd','date_time']]\n",
    "        self.X_train = self.train_data[self.variables]\n",
    "        self.y_train = self.train_data['price_usd']\n",
    "        self.X_val = self.val_data[self.variables]\n",
    "        self.y_val = self.val_data['price_usd']\n",
    "        self.X_test = self.test_data[self.variables]\n",
    "        self.y_test = self.test_data['price_usd']\n",
    "        return self.X_train, self.y_train, self.X_val, self.y_val, self.X_test, self.y_test\n",
    "\n",
    "    def get_normalized_X_y(self):\n",
    "        normalizer = Normalizer().fit(self.X_train) \n",
    "        self.X_train_normalized = normalizer.transform(self.X_train)\n",
    "        self.X_val_normalized = normalizer.transform(self.X_val)\n",
    "        self.X_test_normalized = normalizer.transform(self.X_test)\n",
    "        return self.X_train_normalized, self.X_val_normalized, self.X_test_normalized\n",
    "    \n",
    "    def get_standardized_X_y(self):\n",
    "        # usign min-max scaler to standardized\n",
    "        scaler = MinMaxScaler().fit(self.X_train)\n",
    "        self.X_train_standardized = scaler.transform(self.X_train)\n",
    "        self.X_val_standardized = scaler.transform(self.X_val)\n",
    "        return self.X_train_standardized, self.X_val_standardized, self.X_test_standardized \n",
    "\n",
    "    def get_RMSE(self,y_pred,y_true,data):\n",
    "        return np.sqrt(sum((y_pred - y_true)**2)/len(data))\n",
    "    \n",
    "    # updated: adding y_pred_test and test_RMSE\n",
    "    def get_modeling_result(self):\n",
    "        reg = self.model.fit(self.X_train, self.y_train)\n",
    "        y_pred_val = reg.predict(self.X_val)\n",
    "        y_pred_train = reg.predict(self.X_train)\n",
    "        y_pred_test = reg.predict(self.X_test)\n",
    "        val_RMSE = self.get_RMSE(y_pred_val, self.y_val, self.val_data)\n",
    "        train_RMSE = self.get_RMSE(y_pred_train ,self.y_train, self.train_data)\n",
    "        test_RMSE = self.get_RMSE(y_pred_test ,self.y_test, self.test_data)\n",
    "        print('training RMSE:',train_RMSE)\n",
    "        print('valiation RMSE:',val_RMSE)\n",
    "        print('test RMSE:',test_RMSE)\n",
    "        return y_pred_train, y_pred_val, y_pred_test\n",
    "\n",
    "    def get_normalized_modeling_result(self):\n",
    "        reg = self.model.fit(self.X_train_normalized, self.y_train)\n",
    "        y_pred_val = reg.predict(self.X_val_normalized)\n",
    "        y_pred_train = reg.predict(self.X_train_normalized)\n",
    "        val_RMSE = self.get_RMSE(y_pred_val, self.y_val, self.val_data)\n",
    "        train_RMSE = self.get_RMSE(y_pred_train ,self.y_train, self.train_data)\n",
    "        print('training RMSE:',train_RMSE)\n",
    "        print('valiation RMSE:',val_RMSE)\n",
    "        return train_RMSE, val_RMSE\n",
    "\n",
    "    def get_standardized_modeling_result(self):\n",
    "        reg = self.model.fit(self.X_train_standardized, self.y_train)\n",
    "        y_pred_val = reg.predict(self.X_val_standardized)\n",
    "        y_pred_train = reg.predict(self.X_train_standardized)\n",
    "        val_RMSE = self.get_RMSE(y_pred_val, self.y_val, self.val_data)\n",
    "        train_RMSE = self.get_RMSE(y_pred_train ,self.y_train, self.train_data)\n",
    "        print('training RMSE:',train_RMSE)\n",
    "        print('valiation RMSE:',val_RMSE)\n",
    "        return train_RMSE, val_RMSE\n",
    "\n",
    "class PropModeling():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_data(self):\n",
    "        train = pd.read_csv('../expediadata/train.csv')\n",
    "        test = pd.read_csv('../expediadata/test.csv')\n",
    "        cols_train_only = [col for col in train.columns.unique().tolist() if col not in test.columns.unique().tolist()]\n",
    "        train = train.drop(columns = cols_train_only)\n",
    "        all_data = pd.concat([train, test], ignore_index=True)\n",
    "        # get features\n",
    "        comp_features = ['comp1_rate','comp1_inv','comp1_rate_percent_diff','comp2_inv','comp2_rate','comp2_rate_percent_diff','comp3_rate','comp3_inv','comp3_rate_percent_diff','comp4_rate','comp4_inv','comp4_rate_percent_diff','comp5_rate','comp5_inv','comp5_rate_percent_diff','comp6_rate','comp6_inv','comp6_rate_percent_diff','comp7_rate','comp7_inv','comp7_rate_percent_diff','comp8_rate','comp8_inv','comp8_rate_percent_diff']\n",
    "        user_features = ['visitor_hist_starrating','visitor_hist_adr_usd','srch_query_affinity_score','orig_destination_distance','site_id','visitor_location_country_id','srch_id']\n",
    "        other_features = ['random_bool']\n",
    "        time_features = ['date_time']\n",
    "        all_data = all_data.drop(columns = comp_features)\n",
    "        all_data = all_data.drop(columns = user_features)\n",
    "        all_data = all_data.drop(columns = other_features)\n",
    "        all_data['date_time'] = pd.to_datetime(all_data.date_time)\n",
    "        all_data.sort_values(by=['date_time'],inplace=True)\n",
    "        all_data = all_data.reset_index(drop=True)\n",
    "        \n",
    "        # change id to popularity\n",
    "        \n",
    "        # handle country\n",
    "        country_counts = all_data['prop_country_id'].value_counts()\n",
    "\n",
    "        d = {}\n",
    "        for ID in country_counts.index:\n",
    "            d[ID] = country_counts[ID]\n",
    "        country_id = all_data['prop_country_id'].tolist()\n",
    "        country_pop = []\n",
    "        for ID in country_id:\n",
    "            country_pop.append(d[ID])\n",
    "        all_data['country_value_counts'] = country_pop\n",
    "        city_counts = all_data['srch_destination_id'].value_counts()\n",
    "\n",
    "        # handle city\n",
    "        city = {}\n",
    "        for ID in city_counts.index:\n",
    "            city[ID] = city_counts[ID]\n",
    "        city_id = all_data['srch_destination_id'].tolist()\n",
    "        city_pop = []\n",
    "        for ID in city_id:\n",
    "            city_pop.append(city[ID])\n",
    "        all_data['city_value_counts'] = city_pop\n",
    "\n",
    "        all_data = all_data.drop(columns = 'prop_country_id')\n",
    "        all_data = all_data.drop(columns = 'srch_destination_id')        \n",
    "        return all_data\n",
    "    \n",
    "    def prop_modeling(self, all_data, prop_id):\n",
    "\n",
    "        prop = all_data[all_data['prop_id']==prop_id]\n",
    "\n",
    "        all_data_t = prop.set_index('date_time')\n",
    "        prop_day = all_data_t.resample('D').median()\n",
    "        prop_day.count()\n",
    "\n",
    "        prop_day = prop_day.drop(columns = 'prop_id')\n",
    "        prop_day = prop_day.fillna(prop_day.median())\n",
    "\n",
    "        \n",
    "        variables = [col for col in prop_day.columns.unique().tolist() if col not in ['price_usd']]\n",
    "        model_prop_e = modeling_pipeline(prop_day, ElasticNet(), variables)\n",
    "        train_data, val_data, test_data = model_prop_e.split_data()\n",
    "        X_train,y_train,X_val,y_val,X_test,y_test = model_prop_e.get_X_y()\n",
    "        y_pred_train, y_pred_val, y_pred_test = model_prop_e.get_modeling_result()\n",
    "        \n",
    "        return y_pred_train, y_pred_val, y_pred_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 36.18824539994979\n",
      "valiation RMSE: 67.10979163098759\n",
      "test RMSE: 64.33389846094522\n",
      "y_pred_train: [160.05535553 166.68051522 180.60275946 189.73122497 150.53254613\n",
      " 147.46284121 152.92063352 186.34577026 153.79262252 152.89271071\n",
      " 203.52506601 149.28552065 146.08586364 151.47180867 155.31942694\n",
      " 146.53880064 211.24708227 143.76962354 164.14829543 133.42537853\n",
      " 139.61945533 235.86077129 167.7037502  149.50471996 151.3319906\n",
      " 138.02993592 138.56947622 153.75783035 155.20997839 147.2390507\n",
      " 150.30875562 145.19258075 149.39409272 147.46284121 154.50155464\n",
      " 154.62464989 149.23870487 263.27316351 144.12252999 152.19123061\n",
      " 143.76962354 135.4997713  162.81136583 146.43960623 160.28120121\n",
      " 145.38385724 152.57901608 148.39878056 155.64872101 144.16934577\n",
      " 137.1185962  158.44636018 142.90331226 138.02993592 132.91376104\n",
      " 152.0054329  138.56947622 144.16934577 142.39264597 134.960231\n",
      " 145.41637126 161.03382989 160.76489588 146.21581572 144.95073341\n",
      " 164.1503506  175.86447819 161.78813086 171.75890417 208.14945453\n",
      " 156.07380468 174.12279619 140.30019638 150.84829592 184.77840378\n",
      " 162.64136579 163.6108103  211.97483704 160.76489588 151.55578111\n",
      " 144.70888607 142.66241612 179.40524367 173.08866764 179.36892314\n",
      " 138.02993592 181.54329001 145.41637126 169.22054584 173.11761804\n",
      " 146.43960623 151.84360808 160.76489588 143.1461108  173.09497001\n",
      " 153.33164477 137.00670095 162.32231353 140.77929985 212.13500753\n",
      " 132.43006637 151.55578111 168.9786985  205.0797496  158.95568207\n",
      " 137.00670095 159.78764055 144.93267659 147.2390507  150.53254613\n",
      " 158.71613033 144.2251914  140.30019638 134.960231   196.62325039\n",
      " 170.77345512 154.14179136 152.33257755 157.07167821 164.05671904\n",
      " 168.08438802 192.24333277 188.26830882 201.01267735 179.88893834\n",
      " 158.20680845 157.70662615 168.00838141 194.58749569 145.19258075\n",
      " 171.292643   172.28795516 169.48947985 152.09532141 169.18803182\n",
      " 144.19726859 152.35522557 155.51793279 144.39313628 154.84760426\n",
      " 151.89945371 171.4763491  140.85779351 140.61594617 192.25960698\n",
      " 147.50698146 148.48607618 190.97825046 171.36678589 210.35927816\n",
      " 160.41115329 152.57901608 165.65728025 191.33801374 147.77756342] y_pred_val: [154.62548603 166.29667967 172.02048061 156.44816547 155.8034885\n",
      " 147.75066818 162.96924073 156.98770577 190.97825046 157.25542076\n",
      " 157.22955311 174.06695056 169.59096257 148.21171483 155.64872101\n",
      " 160.0574107  175.94547563 154.29863867 171.55484276 157.18170975\n",
      " 151.55118991 151.8715309  140.83973669 149.33931111 154.26842026\n",
      " 143.5633422  183.54583549 145.09894919 131.89052607 172.81992507\n",
      " 177.45240527 158.09491319 156.98770577 134.20676617 143.36990131\n",
      " 196.05591793 159.5178704  163.40382402] y_pred_test [155.02520826 159.62976565 158.23473126 141.72315359 145.41637126\n",
      " 144.16934577 154.00197329 168.4391582  146.75535602 156.67195598\n",
      " 148.53102824 132.91376104 141.32343136 167.92754071 177.89831402\n",
      " 152.89271071 149.82300578 157.18357347 142.12287582 160.54110537\n",
      " 157.47140045 170.82724559 148.04836115 159.0161189  145.89547473\n",
      " 153.91594568 138.56947622 161.07859051 159.41481355 147.778591\n",
      " 169.26447031 139.5927112  146.48558587 152.46712083 221.13575941\n",
      " 157.21149629 171.85048056 148.80182597 178.58650792 151.60176075\n",
      " 154.94123582 179.49682006 158.01094075 158.17429443 145.97396838\n",
      " 153.91800085 197.80971788 144.3944164  166.39268825]\n"
     ]
    }
   ],
   "source": [
    "p = PropModeling()\n",
    "p_data = p.load_data()\n",
    "y_pred_train, y_pred_val, y_pred_test=p.prop_modeling(p_data, 134232)\n",
    "print('y_pred_train:',y_pred_train,'y_pred_val:',y_pred_val,'y_pred_test',y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 17.518946066940984\n",
      "valiation RMSE: 21.317406545873936\n",
      "test RMSE: 15.633332183156323\n",
      "y_pred_train: [ 94.9118055   87.75956599  89.23358553  92.38855685  87.12784333\n",
      "  86.91726911  87.33841755  93.55035705  92.8060633   96.17525082\n",
      "  92.39219884  91.54625997  95.54352816  89.23358553  89.76002108\n",
      "  90.91089532  88.18071443  87.54899177  94.07315061  89.65473397\n",
      "  90.39174374  95.54352816  89.65473397  89.65473397  90.07588241\n",
      "  89.65473397  90.70760507  95.43824105  89.02301131  90.28645663\n",
      "  88.9177242   89.86530819  88.28600154  89.02301131  89.02301131\n",
      "  89.44415975  87.97014021  88.18071443  87.54899177  88.70714998\n",
      "  89.23358553  88.81243709  87.44370466  87.12784333  89.76002108\n",
      "  86.07497223  87.75956599  87.02255622  93.22721174  86.49612067\n",
      "  85.65382379  85.44324957  84.81152691  85.33796246  86.91726911\n",
      "  90.48974688  85.96968512  91.12146954  89.76002108  85.23267535\n",
      "  88.18071443  96.80697348  92.60277306  90.91817929  90.06859844\n",
      "  87.75956599  95.9646766   91.9710504   95.75410238  95.75410238\n",
      "  93.22721174  89.86530819  93.33978283  93.44506994  90.39174374\n",
      "  95.85938949  89.23358553  96.06996371  90.91089532 101.02574186\n",
      "  97.44598012  95.75410238  89.44415975  91.9710504   96.38582504\n",
      "  96.38582504  97.1264768   88.07542732  98.70214146  96.60368324\n",
      "  96.80697348  91.7531922   98.49156724  86.811982    87.75956599\n",
      "  91.9710504   92.59548908  89.86530819  96.28053793  94.9118055\n",
      "  94.06950862  95.96831859  92.81334728  92.60277306  92.38491486\n",
      "  98.0704188   93.22721174  92.60277306  91.65518907  93.23449572\n",
      "  95.44188304  95.12602171  95.9646766   94.80651839  90.07588241\n",
      "  92.07269552  94.28008284  90.07588241  92.17798263  92.49020197\n",
      "  90.18116952  99.1232899   95.75410238  94.06950862  97.43869614\n",
      "  95.75410238  92.59548908  87.12784333  94.70123128  92.49748595\n",
      "  95.43824105  95.12237972  90.59867598  88.81243709  96.59639926\n",
      "  99.96558678  97.2354059   95.75410238  89.33887264  96.59639926\n",
      "  96.38582504  89.65473397  89.44415975  85.65382379  85.86439801\n",
      "  89.76002108  88.18071443  89.9705953   93.23085373  95.86667347\n",
      "  89.23358553  89.23358553  94.80651839  91.33932774  88.39128865] y_pred_val: [93.8589344  93.0239215  92.49748595 94.28008284 94.80651839 93.65564416\n",
      " 94.17843772 90.49703085 93.65200217 97.75819946 89.02301131 91.54990196\n",
      " 94.70851526 90.28645663 89.76002108 93.8589344  91.9710504  90.49703085\n",
      " 87.97014021 91.01982442 90.07588241 96.70168637 90.49703085 98.0704188\n",
      " 87.12784333 89.23358553 91.23404063 87.97014021 89.23358553 89.86530819\n",
      " 92.60277306 88.9177242  97.43869614 87.75956599 91.33932774 93.23085373\n",
      " 90.49703085 90.91817929] y_pred_test [91.9710504  88.28600154 90.39174374 96.06996371 93.65564416 95.96831859\n",
      " 92.49748595 90.07588241 87.23313044 91.33932774 94.49065706 87.75956599\n",
      " 87.54899177 93.65564416 91.12875352 91.23039864 95.54352816 90.49703085\n",
      " 88.49657576 88.60186287 95.33295394 93.43778596 92.06905353 88.60186287\n",
      " 89.65473397 95.01709261 93.01663752 93.23449572 89.02301131 89.86530819\n",
      " 90.49703085 90.70760507 89.12829842 87.8648531  95.54352816 87.54899177\n",
      " 94.70123128 89.44415975 89.33887264 87.33841755 90.70396309 90.60231796\n",
      " 91.12875352 93.8589344  97.22812192 95.33295394 89.23358553 91.23404063\n",
      " 94.49065706]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train, y_pred_val, y_pred_test=p.prop_modeling(p_data, 104517)\n",
    "print('y_pred_train:',y_pred_train,'y_pred_val:',y_pred_val,'y_pred_test',y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 20.39471671636198\n",
      "valiation RMSE: 15.02179412127364\n",
      "test RMSE: 12.792545865148934\n",
      "y_pred_train: [105.18742434  98.01342469  99.26091888 104.35576154  97.59759329\n",
      "  96.55801479  97.59759329 103.73110642 103.31618305 106.64283424\n",
      " 102.58757007 102.22417161 107.37053919  99.46883458  99.88466598\n",
      " 101.3409839   98.42925608  98.63717178 102.37965437 100.92424448\n",
      " 100.71632878 106.01908714  99.78070813  99.98862383 100.30049738\n",
      "  99.98862383 100.82028663 105.81117144  99.26091888  98.84508748\n",
      "  99.05300318 100.09258168  98.63717178  99.05300318  99.26091888\n",
      "  99.67675028  98.22134039  98.42925608  97.90946684  98.22134039\n",
      "  99.57279243 101.80834021  97.70155114  97.38967759 100.50841308\n",
      "  96.35009909  98.01342469  97.38967759 103.73201445  97.28571974\n",
      "  95.93426769  95.51843629  95.10260489  98.37773117  96.76593049\n",
      " 101.02911035  95.93426769 101.65285745  99.98862383  96.76593049\n",
      "  98.01342469 107.57845489 102.69152792 101.23611803 100.61327896\n",
      "  98.63717178 109.03386478 102.17173867 107.05866564 106.22700284\n",
      " 103.52409875 100.09258168 106.74588406 103.73110642 100.50841308\n",
      " 106.22700284  99.88466598 106.53887639 102.3805624  111.11211375\n",
      " 107.99337826 106.22700284 100.71632878 101.85986513 107.05866564\n",
      " 101.85986513 106.53796836  98.42925608 109.13782263 106.74588406\n",
      " 107.26658134 102.27660455 109.55365403  97.38967759  99.05300318\n",
      " 102.58757007 103.10826735 100.09258168 106.74679209 104.35576154\n",
      " 103.93993015 103.10735932 103.00340147 103.21131717 104.35576154\n",
      " 109.96948543 103.73201445 102.79548577 101.85986513 103.73110642\n",
      " 101.34007588 103.62714857 107.05866564 103.93993015 100.92424448\n",
      "  99.88466598 106.01908714 101.75590728 105.39534004 103.0043095\n",
      " 100.40445523 109.13782263 103.47166581 104.56367724 107.47449704\n",
      " 106.74679209 100.97667742  97.90946684 106.64283424 102.58757007\n",
      " 106.22700284 105.49929789 103.93993015  99.88466598 107.05866564\n",
      " 110.38531683 107.16171546 104.35576154  99.05300318 107.47449704\n",
      " 106.64283424  99.46883458  99.67675028  95.93426769  96.35009909\n",
      "  99.67675028  98.42925608 100.09258168 101.13216018 106.01817911\n",
      "  99.46883458  99.15696103 106.01908714 101.54799158 100.71632878] y_pred_val: [105.18742434 103.83506427 103.83506427 104.77159294 101.96382297\n",
      " 103.83506427 104.45881137 101.75590728 106.22700284 110.80114823\n",
      "  99.26091888 101.02820233 104.77068492 100.71632878  99.78070813\n",
      "  98.84508748 102.37965437 100.71632878  98.22134039 104.35576154\n",
      " 100.30049738 108.09824413 103.10735932 108.51407553  97.59759329\n",
      " 100.09258168 102.79548577  98.63717178  98.01342469 100.09258168\n",
      " 102.58757007  98.22134039 107.37053919  97.90946684 102.06778082\n",
      "  99.26091888  99.88466598 102.27569652] y_pred_test [102.17173867  98.42925608 100.71632878 100.71632878 103.83506427\n",
      " 106.27852775 102.79548577  99.88466598  98.11738254 101.54799158\n",
      " 105.39534004 102.69243595  97.80550899 101.96382297 101.34007588\n",
      "  98.63717178 106.01908714 101.65194943  98.74112963  98.84508748\n",
      " 106.22700284 103.93993015 102.27660455  98.42925608  99.67675028\n",
      " 105.60325574 103.52409875 103.41923287  99.78070813 100.09258168\n",
      "  99.46883458 100.50841308  99.15696103  98.11738254 100.09258168\n",
      "  97.80550899 105.18742434 100.30049738  99.57279243  97.18176189\n",
      " 101.08063527  99.26091888 100.19653953 103.73201445 103.31618305\n",
      " 105.81117144  99.46883458 103.00340147 105.18742434]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train, y_pred_val, y_pred_test=p.prop_modeling(p_data, 124342)\n",
    "print('y_pred_train:',y_pred_train,'y_pred_val:',y_pred_val,'y_pred_test',y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = [38837,78866,107212,31962,9812,103937,54906,105449,29633,135030,51653,55225,27982,78642,132817,25583,59632,109545,38898,9959,118206,29559,48625,107721,18380\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 173.73743528574335\n",
      "valiation RMSE: 18.71778637864807\n",
      "test RMSE: 17.536148732118\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 21.61374370947528\n",
      "valiation RMSE: 20.344562915152064\n",
      "test RMSE: 17.60478938289083\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 18.85413768487824\n",
      "valiation RMSE: 22.43610197696458\n",
      "test RMSE: 53.4267132609482\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 12.162693221053607\n",
      "valiation RMSE: 9.737198229231595\n",
      "test RMSE: 13.07908190742812\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 12.362533785396057\n",
      "valiation RMSE: 27.4579839919458\n",
      "test RMSE: 26.233341260090818\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 24.29936888033349\n",
      "valiation RMSE: 58.84888895991391\n",
      "test RMSE: 39.97310811188886\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 42.59783906966689\n",
      "valiation RMSE: 90.21364653160359\n",
      "test RMSE: 42.31775029905332\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 23.603991718715534\n",
      "valiation RMSE: 22.327412368579655\n",
      "test RMSE: 26.334230350158634\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 24.53735098364037\n",
      "valiation RMSE: 20.514795652165493\n",
      "test RMSE: 18.83559181102705\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 43.140184027541046\n",
      "valiation RMSE: 87.53803263586241\n",
      "test RMSE: 126.34304074225241\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 15.154892807989128\n",
      "valiation RMSE: 28.270491729796873\n",
      "test RMSE: 41.38185709324646\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 33.79800810689531\n",
      "valiation RMSE: 48.19858264556433\n",
      "test RMSE: 73.11731401730258\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 11333.403060197947\n",
      "valiation RMSE: 1222.874464807477\n",
      "test RMSE: 1144.2585833063038\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 13.723375723748012\n",
      "valiation RMSE: 10.92759005732669\n",
      "test RMSE: 11.518748128925598\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 21.23143543030542\n",
      "valiation RMSE: 19.893561367114668\n",
      "test RMSE: 21.973120340993194\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 15.257254488151801\n",
      "valiation RMSE: 25.94105322185546\n",
      "test RMSE: 36.560590673382876\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 76.41559301310389\n",
      "valiation RMSE: 55.86592879195141\n",
      "test RMSE: 53.81986759594416\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 10.116727919465907\n",
      "valiation RMSE: 7.271383877049437\n",
      "test RMSE: 9.532687379131712\n",
      "----------------------\n",
      "training size: 154\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 28.109354246509042\n",
      "valiation RMSE: 45.014539278718054\n",
      "test RMSE: 41.20748280105013\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 52.32266774653298\n",
      "valiation RMSE: 42.10788625964124\n",
      "test RMSE: 49.146966488823416\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 28.453291105072967\n",
      "valiation RMSE: 20.536256199882896\n",
      "test RMSE: 35.893948440819976\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 7.43737030795058\n",
      "valiation RMSE: 7.011623051448397\n",
      "test RMSE: 10.281204578763194\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 49.77423045305047\n",
      "valiation RMSE: 41.958042452365035\n",
      "test RMSE: 54.45982509428938\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 903.6485883283326\n",
      "valiation RMSE: 85.14188592894467\n",
      "test RMSE: 53.91336020992603\n",
      "----------------------\n",
      "training size: 155\n",
      "validation size: 38\n",
      "test size: 48\n",
      "training RMSE: 34.541182012288154\n",
      "valiation RMSE: 25.319313518787677\n",
      "test RMSE: 31.394828646416997\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in lt:\n",
    "    y_pred_train, y_pred_val, y_pred_test=p.prop_modeling(p_data, i)\n",
    "    print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
